{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobilenet v2 ONNX Runtime on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anlu/miniconda3/envs/onnx/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/anlu/miniconda3/envs/onnx/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models, datasets, transforms as T\n",
    "mobilenet_v2 = models.mobilenet_v2(pretrained=True).to(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拿 pretrained 模型：mobilenet_v2_float.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "x = torch.randn(1, 3, image_height, image_width, requires_grad=True)\n",
    "torch_out = mobilenet_v2(x)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(mobilenet_v2,              # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"mobilenet_v2_float.onnx\", # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=12,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output']) # the model's output names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.backends.mps.is_available()) #the MacOS is higher than 12.3+\n",
    "print(torch.backends.mps.is_built()) #MPS is activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import torch\n",
    "\n",
    "def preprocess_image(image_path, height, width, channels=3):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((width, height), Image.NEAREST)\n",
    "    image_data = np.asarray(image).astype(np.float32)\n",
    "    image_data = image_data.transpose([2, 0, 1]) # transpose to CHW\n",
    "    mean = np.array([0.079, 0.05, 0]) + 0.406\n",
    "    std = np.array([0.005, 0, 0.001]) + 0.224\n",
    "    for channel in range(image_data.shape[0]):\n",
    "        image_data[channel, :, :] = (image_data[channel, :, :] / 255 - mean[channel]) / std[channel]\n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10472  100 10472    0     0  16646      0 --:--:-- --:--:-- --:--:-- 16701\n"
     ]
    }
   ],
   "source": [
    "# Download ImageNet labels\n",
    "!curl -o imagenet_classes.txt https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
    "\n",
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開始推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combination lock 0.13506676\n",
      "padlock 0.11689277\n",
      "coffeepot 0.065020375\n",
      "oil filter 0.041768294\n",
      "strainer 0.04128042\n"
     ]
    }
   ],
   "source": [
    "session_fp32 = onnxruntime.InferenceSession(\"mobilenet_v2_float.onnx\")\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def run_sample(session, image_file, categories):\n",
    "    output = session.run([], {'input':preprocess_image(image_file, image_height, image_width)})[0]\n",
    "    output = output.flatten()\n",
    "    output = softmax(output) # this is optional\n",
    "    top5_catid = np.argsort(-output)[:5]\n",
    "    for catid in top5_catid:\n",
    "        print(categories[catid], output[catid])\n",
    "\n",
    "run_sample(session_fp32, 'beer.JPG', categories)\n",
    "# run_sample(session_fp32, 'test.JPG', categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 量化 Quantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantType\n",
    "import os\n",
    "\n",
    "def preprocess_func(images_folder, height, width, size_limit=0):\n",
    "    image_names = os.listdir(images_folder)\n",
    "    if size_limit > 0 and len(image_names) >= size_limit:\n",
    "        batch_filenames = [image_names[i] for i in range(size_limit)]\n",
    "    else:\n",
    "        batch_filenames = image_names\n",
    "    unconcatenated_batch_data = []\n",
    "\n",
    "    for image_name in batch_filenames:\n",
    "        image_filepath = images_folder + '/' + image_name\n",
    "        image_data = preprocess_image(image_filepath, height, width)\n",
    "        unconcatenated_batch_data.append(image_data)\n",
    "    batch_data = np.concatenate(np.expand_dims(unconcatenated_batch_data, axis=0), axis=0)\n",
    "    return batch_data\n",
    "\n",
    "\n",
    "class MobilenetDataReader(CalibrationDataReader):\n",
    "    def __init__(self, calibration_image_folder):\n",
    "        self.image_folder = calibration_image_folder\n",
    "        self.preprocess_flag = True\n",
    "        self.enum_data_dicts = []\n",
    "        self.datasize = 0\n",
    "\n",
    "    def get_next(self):\n",
    "        if self.preprocess_flag:\n",
    "            self.preprocess_flag = False\n",
    "            nhwc_data_list = preprocess_func(self.image_folder, image_height, image_width, size_limit=0)\n",
    "            self.datasize = len(nhwc_data_list)\n",
    "            self.enum_data_dicts = iter([{'input': nhwc_data} for nhwc_data in nhwc_data_list])\n",
    "        return next(self.enum_data_dicts, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "壓縮模型 mobilenet_v2_float.onnx --> mobilenet_v2_uint8.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX full precision model size (MB): 13.344059944152832\n",
      "ONNX quantized model size (MB): 3.483980178833008\n"
     ]
    }
   ],
   "source": [
    "# change it to your real calibration data set\n",
    "calibration_data_folder = \"calibration_imagenet\"\n",
    "dr = MobilenetDataReader(calibration_data_folder)\n",
    "\n",
    "quantize_static('mobilenet_v2_float.onnx',\n",
    "                'mobilenet_v2_uint8.onnx',\n",
    "                dr)\n",
    "\n",
    "print('ONNX full precision model size (MB):', os.path.getsize(\"mobilenet_v2_float.onnx\")/(1024*1024))\n",
    "print('ONNX quantized model size (MB):', os.path.getsize(\"mobilenet_v2_uint8.onnx\")/(1024*1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開始推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cliff 0.18701226\n",
      "wreck 0.15261108\n",
      "seashore 0.101629\n",
      "volcano 0.09180697\n",
      "breakwater 0.04071354\n"
     ]
    }
   ],
   "source": [
    "session_quant = onnxruntime.InferenceSession(\"mobilenet_v2_uint8.onnx\")\n",
    "run_sample(session_quant, 'test.JPG', categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
